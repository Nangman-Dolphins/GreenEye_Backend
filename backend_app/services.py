import os
import json
import requests
import paho.mqtt.client as mqtt
from influxdb_client import InfluxDBClient, Point, WritePrecision
from influxdb_client.client.write_api import SYNCHRONOUS
import redis
from datetime import datetime, timezone
from werkzeug.utils import secure_filename
import re
import base64
from PIL import Image, ImageEnhance
from io import BytesIO


import csv
from io import StringIO

from .database import get_db_connection, get_device_by_device_id_any

FLASH_MAP = {
    "always_on":  {"flash_en": 1, "flash_nt": 1},  # Ï£º/Ïïº Î™®Îëê ÌîåÎûòÏãú
    "always_off": {"flash_en": 0, "flash_nt": 0},  # Ìï≠ÏÉÅ ÎÅî
    "night_off":  {"flash_en": 1, "flash_nt": 0},  # Ï£ºÍ∞ÑÎßå Ïº¨
}

def _publish_conf(device_id: str, payload: dict):
    """GreenEye/conf/{device_id} Î°ú retain publish"""
    topic = f"GreenEye/conf/{device_id}"
    body = json.dumps(payload, ensure_ascii=False)
    mqtt_client.publish(topic, body, qos=1, retain=True)

from .inference import model_manager

from dotenv import load_dotenv
load_dotenv(dotenv_path=".env", override=False)
if os.getenv("ENV_MODE", "local") == "local":
    load_dotenv(dotenv_path=".env.local", override=True)

# ÏïàÏ†ÑÌïú JSON ÎîîÏΩîÎçî (BOM/ÏûëÏùÄÎî∞Ïò¥Ìëú/ÏûòÎ™ªÎêú Ïù¥Ïä§ÏºÄÏù¥ÌîÑ Î≥¥Ï†ï)
def _safe_json_loads(b: bytes):
    raw = b  # ÏõêÎ≥∏ Î≥¥Í¥Ä
    s = None
    try:
        s = raw.decode("utf-8")
    except UnicodeDecodeError:
        s = raw.decode("utf-8-sig", errors="replace")

    t = s.strip()

    # Ïñë ÎÅùÏù¥ ÏûëÏùÄÎî∞Ïò¥ÌëúÎ°ú Í∞êÏã∏Ï†∏ ÏûàÏúºÎ©¥ ÌÅ∞Îî∞Ïò¥ÌëúÎ°ú ÏπòÌôò
    if len(t) >= 2 and t[0] == "'" and t[-1] == "'":
        t = '"' + t[1:-1].replace('"', '\\"') + '"'

    # ÌùîÌïú Ïã§Ïàò: ÌÇ§Í∞Ä ÏûëÏùÄÎî∞Ïò¥ÌëúÎ°ú ÎëòÎü¨Ïã∏Ïù∏ JSON ÌùâÎÇ¥
    # {'a':1,'b':2} -> {"a":1,"b":2}
    if t.startswith("{") and "'" in t and '"' not in t.split(":", 1)[0]:
        t = t.replace("'", '"')

    # Ïó≠Ïä¨ÎûòÏãúÍ∞Ä ÏûòÎ™ª Îì§Ïñ¥ÏôÄ Invalid \escape ÌÑ∞Ïßà Îïå ÏôÑÌôî
    # \n, \t Îì± Ï†ïÏÉÅ ÏãúÌÄÄÏä§Îäî ÎëêÍ≥†, ÎÇòÎ®∏ÏßÄ lone backslashÎäî Ïù¥Ïä§ÏºÄÏù¥ÌîÑ
    import re
    def _fix_bad_backslash(m):
        seq = m.group(0)
        # Ïú†Ìö®Ìïú \", \\, \/, \b, \f, \n, \r, \t, \uXXXX Îäî Í∑∏ÎåÄÎ°ú Îë†
        if re.match(r'\\["\\/bfnrt]', seq) or re.match(r'\\u[0-9a-fA-F]{4}', seq):
            return seq
        return '\\\\' + seq[1:]  # ÎÇòÎ®∏ÏßÄÎäî Î∞±Ïä¨ÎûòÏãú Ïù¥Ïä§ÏºÄÏù¥ÌîÑ

    t = re.sub(r'\\.', _fix_bad_backslash, t)

    return json.loads(t)


def _pick(d: dict, *keys):
    for k in keys:
        if k in d and d[k] is not None:
            return d[k]
    return None

def _to_float(x):
    if x is None: return None
    try: return float(x)
    except (TypeError, ValueError): return None

def _to_int(x):
    if x is None: return None
    try: return int(float(x))  # "40"Ïù¥ÎÇò "40.0"ÎèÑ Ï†ïÏàò 40ÏúºÎ°ú
    except (TypeError, ValueError): return None

    
# --- ÌôòÍ≤Ω Î≥ÄÏàò ---
MQTT_BROKER_HOST = os.getenv("MQTT_BROKER_HOST")
MQTT_BROKER_PORT = int(os.getenv("MQTT_BROKER_PORT", "1883"))
MQTT_USERNAME = os.getenv("MQTT_USERNAME")
MQTT_PASSWORD = os.getenv("MQTT_PASSWORD")

INFLUXDB_URL = os.getenv("INFLUXDB_URL")
INFLUXDB_TOKEN = os.getenv("INFLUXDB_TOKEN")
INFLUXDB_BUCKET = os.getenv("INFLUXDB_BUCKET")
INFLUXDB_ORG = os.getenv("INFLUXDB_ORG")
INFLUX_MEASUREMENT = os.getenv("INFLUX_MEASUREMENT", "sensor_readings")

REDIS_HOST = os.getenv("REDIS_HOST", "redis")
REDIS_PORT = int(os.getenv("REDIS_PORT", "6379"))
REDIS_PASSWORD = os.getenv("REDIS_PASSWORD")

IMAGE_UPLOAD_FOLDER = os.path.join(os.path.abspath(os.path.dirname(__file__)), "images")

# --- ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ ---
mqtt_client = mqtt.Client(mqtt.CallbackAPIVersion.VERSION1)
influxdb_client = None
influxdb_write_api = None
redis_client = None
query_api = None 

# --- Redis Ïó∞Í≤∞ ---
def connect_redis():
    global redis_client
    try:
        redis_client = redis.Redis(
            host=os.getenv("REDIS_HOST", "redis"),
            port=int(os.getenv("REDIS_PORT", "6379")),
            password=os.getenv("REDIS_PASSWORD") or None,
            db=0,
            decode_responses=True,
            health_check_interval=30,
            socket_connect_timeout=5,
            socket_timeout=5,
        )
        redis_client.ping()
        print("Redis connected.")
    except Exception as e:
        redis_client = None
        print(f"Redis connection failed: {e}")

def connect_influxdb():
    """InfluxDB v2 Ïó∞Í≤∞"""
    global influxdb_client, influxdb_write_api, query_api
    try:
        influxdb_client = InfluxDBClient(
            url=INFLUXDB_URL,
            token=INFLUXDB_TOKEN,
            org=INFLUXDB_ORG,
            timeout=30000,
        )
        influxdb_write_api = influxdb_client.write_api(write_options=SYNCHRONOUS)
        query_api = influxdb_client.query_api()
        print("InfluxDB connected.")
    except Exception as e:
        influxdb_client = None
        influxdb_write_api = None
        print(f"InfluxDB connection failed: {e}")

# --- MQTT ÏΩúÎ∞± ---
def on_connect(client, userdata, flags, rc):
    if rc == 0:
        print("MQTT Broker Connected successfully")
        client.subscribe("GreenEye/data/#")
        print("Subscribed to MQTT topic 'GreenEye/data/#'")
    else:
        print(f"Failed to connect to MQTT broker, return code {rc}")

def _parse_mqtt_payload(b: bytes):
    s = b.decode("utf-8", "replace").strip()
    # 1Ï∞®: Ï†ïÏÉÅ JSON ÏãúÎèÑ
    try:
        return json.loads(s)
    except Exception:
        pass
    # 2Ï∞®: ÌùîÌïú Ïò§Î•ò Î≥¥Ï†ï
    t = s.replace("'", '"')  # ÏûëÏùÄÎî∞Ïò¥Ìëú -> ÌÅ∞Îî∞Ïò¥Ìëú
    # {key: ...} ÌòïÌÉúÏùò ÌÇ§Ïóê Îî∞Ïò¥Ìëú Î∂ôÏù¥Í∏∞
    t = re.sub(r'([{,]\s*)([A-Za-z_][A-Za-z0-9_]*)\s*:', r'\1"\2":', t)
    # device_id / time Í∞íÏù¥ Îî∞Ïò¥Ìëú ÏóÜÏù¥ Ïò¨ Îïå Î≥¥Ï†ï
    t = re.sub(r'("device_id"\s*:\s*)([A-Za-z0-9_\-]+)', r'\1"\2"', t)
    t = re.sub(r'("(_time|time)"\s*:\s*)([^",}\s][^,}\s]*)', r'\1"\3"', t)
    return json.loads(t)

# --- MQTT ÏΩúÎ∞± ---
def on_message(client, userdata, msg):
    print(f"MQTT Message received: Topic - {msg.topic}")
    if msg.topic.startswith("GreenEye/data/"):
        try:
            payload = _safe_json_loads(msg.payload)
            process_incoming_data(msg.topic, payload)
        except Exception as e:
            print(f"Error processing incoming data: {e}")
            # ÎîîÎ≤ÑÍπÖÏö© ÌéòÏù¥Î°úÎìú ÌîÑÎ¶¨Î∑∞
            try:
                print("[payload preview]", msg.payload.decode("utf-8", "replace")[:200])
            except:
                pass


def connect_mqtt():
    # ‚úÖ ÌôòÍ≤ΩÎ≥ÄÏàòÏóêÏÑú Í∞ÄÏ†∏Ïò§Îêò ÏóÜÏúºÎ©¥ Í∏∞Î≥∏Í∞í ÏÇ¨Ïö©
    broker_host = os.getenv("MQTT_BROKER_HOST", "localhost")
    broker_port = int(os.getenv("MQTT_BROKER_PORT", 1883))

    if MQTT_USERNAME and MQTT_PASSWORD:
        mqtt_client.username_pw_set(MQTT_USERNAME, MQTT_PASSWORD)
    
    mqtt_client.on_connect = on_connect
    mqtt_client.on_message = on_message
    
    try:
        mqtt_client.connect(broker_host, broker_port, 60)
        mqtt_client.loop_start()
    except Exception as e:
        print(f"Could not connect to MQTT broker at {broker_host}:{broker_port} ‚Üí {e}")



def write_sensor_data_to_influxdb(measurement, tags, fields, ts=None):
    from influxdb_client import Point, WritePrecision
    from datetime import datetime, timezone

    global influxdb_client, influxdb_write_api
    if influxdb_client is None:
        connect_influxdb()

    # lazy init or recreate write_api
    if influxdb_write_api is None:
        try:
            influxdb_write_api = influxdb_client.write_api(write_options=SYNCHRONOUS)
        except Exception as e:
            print(f"[Influx] write_api init failed: {e}")
            return
    
    point = Point(measurement)
    for k, v in (tags or {}).items():
        point.tag(k, v)
    for k, v in (fields or {}).items():
        # InfluxÎäî float/intÎßå ÌïÑÎìúÏóê ÌóàÏö© ‚Üí NoneÏùÄ Í±¥ÎÑàÎúÄ
        if v is not None:
            point.field(k, v)
    

    # ‚úÖ ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ Î∞òÏòÅ (ISO8601 / epoch seconds / epoch ms Î™®Îëê ÌóàÏö©)
    if ts:
        try:
            ts_dt = None
            if isinstance(ts, (int, float)):
                if ts > 1e12:  # ms
                    ts_dt = datetime.fromtimestamp(ts / 1000.0, tz=timezone.utc)
                else:          # s
                    ts_dt = datetime.fromtimestamp(ts, tz=timezone.utc)
            elif isinstance(ts, str):
                s = ts.strip()
                if s.isdigit():
                    iv = int(s)
                    ts_dt = datetime.fromtimestamp(
                        iv / (1000.0 if iv > 1e12 else 1.0), tz=timezone.utc
                    )
                else:
                    if s.endswith("Z"):
                        s = s[:-1] + "+00:00"
                    ts_dt = datetime.fromisoformat(s)
                    if ts_dt.tzinfo is None:
                        ts_dt = ts_dt.replace(tzinfo=timezone.utc)
            if ts_dt:
                point.time(ts_dt, WritePrecision.NS)
        except Exception as e:
            print(f"[Influx] invalid ts '{ts}': {e} ( ‚Üí server time )")
    lp = point.to_line_protocol()
    print(f"[Influx] write TRY bucket={INFLUXDB_BUCKET} org={INFLUXDB_ORG} lp={lp}")

    # Ïã§Ï†ú Ïì∞Í∏∞ ‚Äî Ïã§Ìå® Ïãú 1Ìöå Ïû¨Ïó∞Í≤∞ ÌõÑ Ïû¨ÏãúÎèÑ
    try:
        lp = point.to_line_protocol()  # üîç ÎîîÎ≤ÑÍπÖÏö©
        print(f"[Influx] write TRY bucket={INFLUXDB_BUCKET} org={INFLUXDB_ORG} lp={lp[:200]}")
        influxdb_write_api.write(bucket=INFLUXDB_BUCKET, org=INFLUXDB_ORG, record=point)
        print("[Influx] write OK")
    except Exception as e:
        print(f"[Influx] write failed once, retrying with fresh client: {e}")
        try:
            influxdb_client.close() if influxdb_client else None
        except Exception:
            pass
        influxdb_client = InfluxDBClient(
            url=INFLUXDB_URL, token=INFLUXDB_TOKEN, org=INFLUXDB_ORG, timeout=30000
        )
        influxdb_write_api = influxdb_client.write_api(write_options=SYNCHRONOUS)
        try:
            influxdb_write_api.write(bucket=INFLUXDB_BUCKET, org=INFLUXDB_ORG, record=point)
            print("[Influx] write OK after reconnect")
        except Exception as e2:
            print(f"[Influx] write retry failed: {e2}")


def query_influxdb_data(query: str):
    print(f"[DEBUG] Ïã§ÌñâÌï† Flux ÏøºÎ¶¨:\n{query}")
    try:
        url = f"{INFLUXDB_URL}/api/v2/query"
        headers = {
            "Authorization": f"Token {INFLUXDB_TOKEN}",
            "Content-Type": "application/vnd.flux",
            "Accept": "application/csv"
        }
        params = {"org": INFLUXDB_ORG}

        response = requests.post(url, params=params, data=query.encode("utf-8"), headers=headers)
        response.raise_for_status()

        decoded = response.content.decode("utf-8", errors="replace")
        
        
        # üîç ÏùëÎãµ ÌôïÏù∏Ïö© ÌîÑÎ¶¨Î∑∞/Í∏∏Ïù¥
        preview = "\n".join(decoded.splitlines()[:20])
        print(f"[DEBUG] Influx CSV bytes={len(response.content)} / lines_preview=\n{preview}")

        rows = parse_csv_result(decoded)
        print(f"[DEBUG] parsed_rows_count={len(rows)}")
        if rows:
            print(f"[DEBUG] parsed_sample_keys={list(rows[0].keys())}")
        return rows
        print(f"[DEBUG] parsed_rows={len(rows)}")
        return rows
    except Exception as e:
        print(f"[InfluxDB] Query failed: {e}")
        return None


def set_redis_data(key: str, value):
    if not redis_client:
        print(f"[REDIS] client not ready; skip set {key}")
        return
    try:
        redis_client.set(key, json.dumps(value))
        print(f"[REDIS] SET {key} -> {value}")
    except Exception as e:
        print(f"Error setting data in Redis: {e}")

def get_redis_data(key: str):
    if not redis_client:
        return None
    try:
        data = redis_client.get(key)
        if not data:
            return None
        # ‚úÖ RedisÏóê BOM/ÎπÑÌëúÏ§Ä JSONÏù¥ Îì§Ïñ¥ÏôÄÎèÑ Î≥µÍµ¨ ÏãúÎèÑ
        if isinstance(data, str):
            try:
                return json.loads(data)
            except Exception:
                return _safe_json_loads(data.encode("utf-8"))
        return _safe_json_loads(data)
    except Exception as e:
        print(f"Error getting data from Redis: {e}")
        return None

# === Ï∂îÎ°† Ìï®Ïàò Ï∂îÍ∞Ä ===
def run_inference_on_image(device_id: str, image_path: str):
    """
    Ï†ÄÏû•Îêú Ïù¥ÎØ∏ÏßÄ ÌååÏùºÏóê ÎåÄÌï¥ AI Ï∂îÎ°†ÏùÑ ÏàòÌñâÌï©ÎãàÎã§.
    
    Args:
        device_id: ÎîîÎ∞îÏù¥Ïä§ ID
        image_path: Ïù¥ÎØ∏ÏßÄ ÌååÏùº Í≤ΩÎ°ú
        
    Returns:
        Ï∂îÎ°† Í≤∞Í≥º ÎîïÏÖîÎÑàÎ¶¨
    """
    try:
        print(f"[AI] Starting inference for device {device_id}, image: {image_path}")
        
        # Ïù¥ÎØ∏ÏßÄ ÌååÏùº ÏùΩÍ∏∞
        with open(image_path, 'rb') as f:
            image_bytes = f.read()
        
        # Í∏∞Î≥∏ plant_type ÏÑ§Ï†ï (ÎÇòÏ§ëÏóê deviceÎ≥ÑÎ°ú ÏÑ§Ï†ï Í∞ÄÎä•ÌïòÎèÑÎ°ù ÌôïÏû• Í∞ÄÎä•)
        # Ïòà: DBÏóêÏÑú device_idÎ°ú plant_type Ï°∞Ìöå
        plant_type = "default"  # Í∏∞Î≥∏Í∞í, Ïã§Ï†úÎ°úÎäî DBÎÇò ÏÑ§Ï†ïÏóêÏÑú Í∞ÄÏ†∏ÏôÄÏïº Ìï®
        
        # device Ï†ïÎ≥¥ÏóêÏÑú plant_type Í∞ÄÏ†∏Ïò§Í∏∞ ÏãúÎèÑ
        device_info = get_device_by_device_id_any(device_id)
        if device_info and device_info.get('plant_type'):
            plant_type = device_info['plant_type']
        
        # model_managerÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ï∂îÎ°† ÏàòÌñâ
        result = model_manager.predict(image_bytes, plant_type)

        if "error" in result:
            result['comment'] = get_plant_comment("_error")
        else:
            predicted_label = result.get("predicted_label", "")
            
            # 1. Ï£ºÏöî ÌÇ§ (e.g., "Rose_healthy")
            specific_key = f"{plant_type}_{predicted_label}"
            
            # 2. ÎåÄÏ≤¥ ÌÇ§ (e.g., "healthy")Îäî predicted_label ÏûêÏ≤¥
            
            # ÏàòÏ†ïÎêú Ìï®Ïàò Ìò∏Ï∂ú
            result['comment'] = get_plant_comment(primary_key=specific_key, fallback_key=predicted_label)
        
        # ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ Ï∂îÍ∞Ä
        result['timestamp'] = datetime.utcnow().isoformat()
        result['device_id'] = device_id
        result['plant_type'] = plant_type
        
        print(f"[AI] Inference completed for {device_id}: {result}")
        return result
        
    except FileNotFoundError:
        error_msg = f"Image file not found: {image_path}"
        print(f"[AI] Error: {error_msg}")
        return {
            "error": error_msg,
            "device_id": device_id,
            "timestamp": datetime.utcnow().isoformat()
        }
    except Exception as e:
        error_msg = f"Inference failed: {str(e)}"
        print(f"[AI] Error: {error_msg}")
        return {
            "error": error_msg,
            "comment": get_plant_comment("_error"), # ÏòàÏô∏ Î∞úÏÉù ÏãúÏóêÎèÑ ÏóêÎü¨ ÏΩîÎ©òÌä∏ Ï∂îÍ∞Ä
            "device_id": device_id,
            "timestamp": datetime.utcnow().isoformat()
        }


# --- Îç∞Ïù¥ÌÑ∞ ÌååÏù¥ÌîÑÎùºÏù∏ ---
def process_incoming_data(topic: str, payload):
    try:
        # Ï∂îÍ∞Ä: ÌòπÏãú Î¨∏ÏûêÏó¥Î°ú Ïò§Î©¥ json.loads Ìïú Î≤à Îçî
        if isinstance(payload, (bytes, str)):
            if isinstance(payload, bytes):
                payload = payload.decode("utf-8", errors="ignore")
            payload = json.loads(payload)

        # ÌÜ†ÌîΩ: GreenEye/data/{DeviceID}
        # ‚úÖ Ìï≠ÏÉÅ 4ÏûêÎ¶¨ short idÎ°ú Ï†ïÍ∑úÌôî (ge-sd-2e52 -> 2e52)
        raw_id = topic.split("/")[-1].strip().lower()
        m = re.fullmatch(r"(?:ge-sd-)?([0-9a-f]{4})", raw_id)
        device_id = m.group(1) if m else raw_id
        print(f"Processing data for device_id: {device_id}")

        dev = get_device_by_device_id_any(device_id)
        mac = dev["mac_address"] if dev else None

        # --- Îç∞Ïù¥ÌÑ∞ Ï¢ÖÎ•òÏóê Îî∞Îùº Î∂ÑÍ∏∞ Ï≤òÎ¶¨ (plant_img ÌÇ§ Ïú†Î¨¥Î°ú ÌåêÎã®) ---
        if "plant_img" in payload:
            try: 
                # Ïù¥ÎØ∏ÏßÄ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
                # ~.jpgÎ°ú ÏÇ¨ÏßÑ ÌååÏùº Ï†ÄÏû•, ~.originÏúºÎ°ú base16 ÌÖçÏä§Ìä∏ ÏõêÎ≥∏ Ï†ÄÏû•
                image_base64 = payload.get("plant_img")
                if image_base64 and isinstance(image_base64, str):
                    image_dec = base64.b64decode(image_base64)

                    brightness_factor = 1.2   # 20% brighter
                    contrast_factor   = 1.2   # 20% more contrast
                    saturation_factor = 3.0   # 300% more saturation
                    sharpness_factor  = 1.3   # 30% more sharpness

                    with Image.open(BytesIO(image_dec)) as img:
                        # === apply enhancements sequentially ===
                        enhancer = ImageEnhance.Brightness(img)
                        img_enhanced = enhancer.enhance(brightness_factor)
                        
                        enhancer = ImageEnhance.Contrast(img_enhanced)
                        img_enhanced = enhancer.enhance(contrast_factor)
                        
                        enhancer = ImageEnhance.Color(img_enhanced)
                        img_enhanced = enhancer.enhance(saturation_factor)

                        enhancer = ImageEnhance.Sharpness(img_enhanced)
                        img_enhanced = enhancer.enhance(sharpness_factor)
                    
                    buffer = BytesIO()
                    img_enhanced.save(buffer, 'JPEG', quality=100)
                    enhanced_image_bytes = buffer.getvalue()


                    image_base16 = base64.b16encode(enhanced_image_bytes)
                    image_base16_str = image_base16.decode('UTF-8')

                    filename = f"{device_id}_{datetime.now().strftime('%Y%m%d%H%M%S')}"
                    filename_jpg = f"{filename}.jpg"
                    filename_origin = f"{filename}.origin"

                    path_jpg = os.path.join(IMAGE_UPLOAD_FOLDER, filename_jpg)
                    path_origin = os.path.join(IMAGE_UPLOAD_FOLDER, filename_origin)

                    os.makedirs(IMAGE_UPLOAD_FOLDER, exist_ok=True)

                    with open(path_jpg, "wb") as f:
                        f.write(enhanced_image_bytes)
                    with open(path_origin, "w", encoding="utf-8") as f:
                        f.write(image_base16_str)

                    if mac:
                        try:
                            with get_db_connection() as conn:
                                conn.execute(
                                    "INSERT INTO plant_images (device_id, mac_address, filename, filepath, timestamp) VALUES (?, ?, ?, ?, ?)",
                                    (device_id, mac, filename, path_jpg, datetime.utcnow().isoformat()),
                                )
                                conn.commit()
                        except Exception as e:
                            print(f"Failed to save image meta to DB for {device_id}: {e}")
                    else:
                        # ÎîîÎ∞îÏù¥Ïä§ ÎØ∏Îì±Î°ùÏù¥Î©¥ plant_imagesÎäî device_id / mac_address NOT NULL ÎïåÎ¨∏Ïóê ÏóêÎü¨ ÎÇòÎãà Ï†ÄÏû• Ïä§ÌÇµ
                        print(f"Skip DB insert for image because device not registered: {device_id}")

                    set_redis_data(f"latest_image:{device_id}", {"filename": filename})
                    print(f"Image saved: {path_jpg}")

                    diagnosis = run_inference_on_image(device_id, path_jpg)
                    set_redis_data(f"latest_ai_diagnosis:{device_id}", diagnosis)
                    print(f"AI inference complete for {device_id}")
            except (base64.binascii.Error, TypeError) as e:
                print(f"Error decoding Base64 string for device {device_id}: {e}")
        else:
            tags = {"device_id": device_id}
            if mac:
                tags["mac_address"] = mac

            # ÌÇ§ ÎßµÌïë(ÏÑúÎ°ú Îã§Î•∏ ÌéåÏõ®Ïñ¥/ÌÖåÏä§Ìä∏ Ìè¨Îß∑ Î™®Îëê ÏàòÏö©)
            battery        = _pick(payload, "battery", "bat_level", "bat")
            temperature    = _pick(payload, "temperature", "amb_temp", "temp")
            humidity       = _pick(payload, "humidity", "amb_humi", "hum")
            light_lux      = _pick(payload, "light_lux", "amb_light", "lux")
            soil_temp      = _pick(payload, "soil_temp")
            soil_moisture  = _pick(payload, "soil_moisture", "soil_humi")
            soil_ec        = _pick(payload, "soil_ec")

            # ÌÉÄÏûÖ Ï∫êÏä§ÌåÖ: batteryÎäî Ï†ïÏàò, ÎÇòÎ®∏ÏßÄÎäî float
            fields = {
                "battery": _to_int(payload.get("battery") or payload.get("bat_level")),
                "temperature": _to_float(payload.get("temperature") or payload.get("amb_temp")),
                "humidity": _to_float(payload.get("humidity") or payload.get("amb_humi")),
                "light_lux": _to_float(payload.get("light_lux") or payload.get("amb_light")),
                "soil_temp": _to_float(payload.get("soil_temp")),
                "soil_moisture": _to_float(payload.get("soil_moisture") or payload.get("soil_humi")),
                "soil_ec": _to_float(payload.get("soil_ec")),
                "comment": payload.get("comment"),
            }
            valid_fields = {k: v for k, v in fields.items() if v is not None}

            if valid_fields:
                ts_str = payload.get("_time") or payload.get("time") or payload.get("timestamp") or None
                # InfluxDB: ÎîîÎ∞îÏù¥Ïä§ ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ Ïö∞ÏÑ†
                write_sensor_data_to_influxdb("sensor_readings", tags, valid_fields, ts=ts_str)

                # Redis Ï∫êÏãú: ÌîÑÎ°†Ìä∏ Ï°∞ÌöåÏö©, ÎèôÏùº ÌÉÄÏûÖ Ïú†ÏßÄ
                redis_doc = {"timestamp": ts_str or datetime.utcnow().isoformat(), **valid_fields}
                set_redis_data(f"latest_sensor_data:{device_id}", redis_doc)
                print(f"Sensor data processed and stored for {device_id}")

    except Exception as e:
        print(f"Error in process_incoming_data for topic {topic}: {e}")

# --- Ïû•Ïπò ÌÜµÏã† (DeviceID Í∏∞Ï§Ä) ---

# Ïù¥ Ìï®ÏàòÎäî ÌòÑÏû¨ ÏÇ¨Ïö©ÎêòÏßÄ ÏïäÏúºÎ©∞, SD Ïû•ÏπòÍ∞Ä ÏûêÏú®Ï†ÅÏúºÎ°ú ÏÑºÏã± Ï£ºÍ∏∞Î•º Í¥ÄÎ¶¨ÌïòÍ∏∞ ÎïåÎ¨∏Ïóê ÏùºÎã® ÏûÑÏãúÎ°ú Ï£ºÏÑù Ï≤òÎ¶¨
# def request_data_from_device(device_id: str, sensor_only: bool = False):
#     topic = f"GreenEye/req/{device_id}"
#     payload = {"req": 1 if sensor_only else 0}
#     mqtt_client.publish(topic, json.dumps(payload))
#     print(f"Sent data request to topic: {topic} payload={payload}")


# ÌîÑÎ¶¨ÏÖã Î™®Îìú Ï†ÑÏÜ° Ìï®Ïàò Ï†ïÏùò
def send_mode_to_device(device_id: str, 
                        mode_char: str,
                        night_option: str ):
    mode = (mode_char or "M").upper()[:1]
    nht = 1 if night_option == "night_on" else 0
    
    base = {"pwr_mode": mode, "nht_mode": nht}

    payload = dict(base)

    _publish_conf(device_id, payload)
    return payload

def send_config_to_device(device_id: str, config_payload: dict):
    """
    sends a configuration payload to a device via mqtt.
    this function is flexible and accepts both high-level keys (like 'mode')
    and low-level keys (like 'pwr_mode').
    """
    if not mqtt_client.is_connected():
        connect_mqtt()

    if not config_payload:
        print(f"[warn] send_config_to_device received an empty payload for {device_id}.")
        return

    if not isinstance(config_payload, dict) or not config_payload:
        print(f"[error] received an invalid or empty payload for {device_id}: {config_payload}")
        return

    topic = f"GreenEye/gardening/{device_id}"
    payload_str = json.dumps(config_payload)

    try:
        # === publish the message with retain flag ===

        info = mqtt_client.publish(topic, payload_str, qos=1, retain=True)
        info.wait_for_publish(timeout=5) # wait for the message to be sent

        if info.rc == 0:
            print(f"successfully sent config to topic: {topic} payload={payload_str}")
        else:
            print(f"failed to send config to {topic}, return code: {info.rc}")

    except Exception as e:
        print(f"an exception occurred while publishing config for {device_id}: {e}")

        
# --- MQTT ÌçºÎ∏îÎ¶¨Ïãú(Ïï±ÏóêÏÑú Í∏∞ÎåÄÌïòÎäî Í≥µÍ∞ú API) ---
def publish_mqtt_message(topic: str, payload, qos: int = 0, retain: bool = False) -> bool:
    """
    Ïï±(app.py)Ïù¥ import Ìï¥ÏÑú Ïì∞Îäî ÌëúÏ§Ä ÌçºÎ∏îÎ¶¨Ïãú Ìï®Ïàò.
    payloadÍ∞Ä dict/listÎ©¥ JSON Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôòÌï¥ÏÑú Ï†ÑÏÜ°.
    MQTT Ïó∞Í≤∞Ïù¥ Ïïà ÎêòÏñ¥ ÏûàÏúºÎ©¥ ÏûêÎèôÏúºÎ°ú Ïó∞Í≤∞ ÏãúÎèÑ.
    """
    try:
        # payloadÎ•º Î¨∏ÏûêÏó¥Î°ú Ï†ïÍ∑úÌôî
        if isinstance(payload, (dict, list)):
            payload_str = json.dumps(payload, ensure_ascii=False)
        else:
            payload_str = str(payload)

        # ÌïÑÏöî Ïãú Ïó∞Í≤∞
        if not mqtt_client.is_connected():
            connect_mqtt()

        info = mqtt_client.publish(topic, payload_str, qos=qos, retain=retain)
        try:
            # Ï†ÑÏÜ° ÏôÑÎ£åÍπåÏßÄ ÏµúÎåÄ 5Ï¥à ÎåÄÍ∏∞ (ÏÑ±Í≥µ Ïãú True)
            info.wait_for_publish(timeout=5)
        except TypeError:
            # ÏùºÎ∂Ä Î≤ÑÏ†ÑÏóêÏÑ† timeout ÌååÎùºÎØ∏ÌÑ∞Í∞Ä ÏóÜÏùÑ Ïàò ÏûàÏùå
            info.wait_for_publish()

        return getattr(info, "rc", 0) == 0
    except Exception as e:
        print(f"Error publishing MQTT message to {topic}: {e}")
        return False

# --- Ìó¨Ïä§Ï≤¥ÌÅ¨Ïö© ---
def is_connected_mqtt():
    return mqtt_client.is_connected()

def is_connected_influx():
    return influxdb_client is not None

def is_connected_redis():
    try:
        return redis_client is not None and redis_client.ping()
    except:
        return False

# --- Ï¥àÍ∏∞Ìôî ---
def initialize_services():
    print("[services] ‚è≥ Connecting to services...")
    connect_mqtt()
    print("[services] ‚úÖ MQTT connected (or tried)")
    connect_influxdb()
    print("[services] ‚úÖ InfluxDB connected (or tried)")
    connect_redis()
    print("[services] ‚úÖ Redis connected (or tried)")
    print("\n--- Initializing Backend Services ---")
    for name in ("connect_mqtt", "connect_influxdb", "connect_redis"):
        func = globals().get(name, None)
        if callable(func):
            try:
                func()
                print(f"{name} ok")
            except Exception as e:
                print(f"{name} failed: {e}")
        else:
            print(f"{name} not defined ‚Äî skipping")
    print("--- All services connection attempts made. ---\n")

def get_influx_client():
    return influxdb_client

__all__ = [
    "connect_influxdb",
    "query_influxdb_data",
    "write_sensor_data_to_influxdb",
    "get_influx_client",
]

def parse_csv_result(decoded_csv: str):
    """
    InfluxDB CSV ÏùëÎãµÏóêÏÑú Ï£ºÏÑù(#...)ÏùÄ Ï†úÍ±∞ÌïòÍ≥†,
    Ìó§Îçî Îß® ÏïûÏóê Îπà Ïª¨ÎüºÏù¥ ÏûàÏúºÎ©¥ Ï†úÍ±∞Ìïú Îí§ DictReaderÎ°ú ÌååÏã±ÌïúÎã§.
    '_time' ÎòêÎäî 'time' Ïª¨ÎüºÏù¥ ÏûàÎäî ÌñâÎßå Î∞òÌôò.
    """
    # 1) Ï§Ñ Îã®ÏúÑ Ï†ïÎ¶¨: Îπà Ï§Ñ/Ï£ºÏÑù Ï†úÍ±∞
    raw_lines = decoded_csv.splitlines()
    lines = [ln for ln in raw_lines if ln and not ln.startswith("#")]
    if not lines:
        print("[DEBUG] parse_csv_result: no non-comment lines")
        return []

    # 2) Ìó§Îçî ÌååÏã± & Îß® Ïïû Îπà Ïª¨Îüº Ï†úÍ±∞
    header_cols = lines[0].split(",")
    drop_first = (len(header_cols) > 0 and header_cols[0] == "")
    if drop_first:
        header_cols = header_cols[1:]

    # 3) Îç∞Ïù¥ÌÑ∞ ÎùºÏù∏ÎèÑ ÎèôÏùºÌïòÍ≤å Ï≤´ Ïª¨Îüº Ï†úÍ±∞
    fixed_data_lines = []
    for ln in lines[1:]:
        cols = ln.split(",")
        if drop_first and len(cols) > 0:
            cols = cols[1:]
        fixed_data_lines.append(",".join(cols))

    # 4) DictReaderÎ°ú Ïû¨Íµ¨ÏÑ±Ìï¥ÏÑú ÏùΩÍ∏∞
    csv_text = ",".join(header_cols) + "\n" + "\n".join(fixed_data_lines)
    reader = csv.DictReader(StringIO(csv_text))

    rows = []
    for r in reader:
        # Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞Îßå ÏàòÏßë
        if r.get("_time") or r.get("time"):
            rows.append(r)

    print(f"[DEBUG] parsed_rows_count={len(rows)}")
    if rows:
        print(f"[DEBUG] parsed_sample_keys={list(rows[0].keys())}")
    return rows

# --- ÌïúÏ§ÑÌèâ Î°úÎçî (Ï∂îÍ∞Ä) ---
_comment_cache = {}

def get_plant_comment(primary_key: str = None, fallback_key: str = None) -> str:
    """
    AIÍ∞Ä ÏòàÏ∏°Ìïú Î†àÏù¥Î∏îÏùÑ Í∏∞Î∞òÏúºÎ°ú ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†ÅÏù∏ ÌïúÏ§ÑÌèâÏùÑ Î∞òÌôòÌï©ÎãàÎã§.
    JSON ÌååÏùºÏùÑ ÏùΩÍ≥† Í∑∏ ÎÇ¥Ïö©ÏùÑ Ï∫êÏãúÏóê Ï†ÄÏû•ÌïòÏó¨ ÏÑ±Îä•ÏùÑ ÏµúÏ†ÅÌôîÌï©ÎãàÎã§.
    """
    global _comment_cache

    if not _comment_cache:
        try:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            comment_file_path = os.path.join(current_dir, 'plant_comments.json')
            with open(comment_file_path, 'r', encoding='utf-8') as f:
                _comment_cache = json.load(f)
            print("[INFO] Plant comments loaded successfully.")
        except Exception as e:
            print(f"[ERROR] Failed to load plant_comments.json: {e}")
            _comment_cache = {
                "_default": "Î∂ÑÏÑù Í≤∞Í≥ºÎ•º ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.",
                "_error": "Î∂ÑÏÑù Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§."
            }

    # 1. Ï£ºÏöî ÌÇ§ (e.g., "Rose_healthy")Î°ú Î®ºÏ†Ä Í≤ÄÏÉâ
    if primary_key:
        comment = _comment_cache.get(primary_key)
        if comment:
            return comment

    # 2. Ï£ºÏöî ÌÇ§Í∞Ä ÏóÜÏùÑ Í≤ΩÏö∞, ÎåÄÏ≤¥ ÌÇ§ (e.g., "healthy")Î°ú Í≤ÄÏÉâ
    if fallback_key:
        comment = _comment_cache.get(fallback_key)
        if comment:
            return comment

    # 3. Îëê ÌÇ§ Î™®Îëê ÏóÜÏùÑ Í≤ΩÏö∞, Í∏∞Î≥∏ Î©îÏãúÏßÄ Î∞òÌôò
    return _comment_cache.get("_default", "Î∂ÑÏÑù Í≤∞Í≥ºÎ•º ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.")